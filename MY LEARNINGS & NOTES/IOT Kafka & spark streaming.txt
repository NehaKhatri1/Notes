




 IoT Components are interconnected devices over the network, which are embedded with sensors, software and smart apps so they can collect and exchange data with each other or with cloud/data centres. The data generated by IoT devices is large in volume and random in nature and needs to be analysed using a big data analytics engine in order to extract the critical information or to understand the user behavioural patterns.

One of the areas in which IoT is paving its way is the connected vehicles. According to Gartner, by 2020, there will be a quarter-billion connected vehicles on the road, which are more automated, providing new in-vehicle services such as enhanced navigation system, real-time traffic updates, weather alerts and integration with monitoring dashboard and smart phones. In order to process the data generated by IoT connected vehicles, data is streamed to big data processors located in the cloud or the data centres. An IoT connected vehicle provides real time information of the vehicle like speed, fuel level, route name, latitude and longitude of vehicle etc. This information can be analysed and data can be extracted and transformed to the final result which can be sent back to the vehicle or to a monitoring dashboard. For example, using the information collected for different vehicles we can analyse and monitor the traffic on a particular route. In this article, we’ll use Apache Spark to analyse and process IoT connected vehicle’s data and send the processed data to a real time traffic monitoring dashboard.






A data ingestion pipeline moves streaming data and batched data from pre-existing databases and data warehouses to a data lake. Businesses with big data configure their data ingestion pipelines to structure their data, enabling querying using SQL-like language. Organization of the data ingestion pipeline is a key strategy when transitioning to a data lake solution. 

For an HDFS-based data lake, tools such as Kafka, Hive, or Spark are used for data ingestion. Kafka is a popular data ingestion tool that supports streaming data. Hive and Spark, on the other hand, move data from HDFS data lakes to relational databases from which data could be fetched for end users. 

